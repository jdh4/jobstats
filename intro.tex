\section{Introduction}
On a high-performance computing (HPC) cluster, users submit jobs to the workload manager which arranges for the work to be carried out on the compute nodes. The job scheduler typically provides only limited tools for monitoring various aspects of the running jobs. Due to the high cost of such clusters and the demand by users for high throughput, it is critical to ensure that the resources are being using properly. Additionally, the complexity of HPC clusters leads to difficult-to-diagnose problems such as file system slowdowns, CPUs being throttled and failed jobs.

To address these matters, various job monitoring platforms have been introduced including Ganglia~\cite{ganglia}, XDMoD~\cite{xdmod}, MAP~\cite{map_platform,map_platform2}, LIKWID~\cite{likwid} and PIKA~\cite{pika}. Some users of these platforms seek greater visualization support and better facilities for working with real-time job metrics. The combination of the Prometheus monitoring framework~\cite{prometheus} and the Grafana visualization toolkit~\cite{grafana} overcome many of shortcomings of previous job monitoring platforms. Kunz et al.~\cite{pascal} used Prometheus and Grafana to detect a variety of anomalous jobs through simulation. The authors were able to automatically detect several types of errant jobs.

In the present work, we introduce the Jobstats job monitoring platform. The platform is based on Prometheus, Grafana and the Slurm~\cite{slurm} job scheduler. The platform has proven to be of great value at our institution which has a data center with 100,000 CPU-cores and 500 GPUs. We discuss Prometheus and how it interacts with the various components of the Jobstats platform in Section~\ref{jobstats_design}. Tools that build on the platform are described in Section~\ref{jobstats_tools}.
